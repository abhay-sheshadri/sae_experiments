{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/phillip_guo/miniconda3/envs/cb/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformer_lens import utils as tl_utils\n",
    "from transformer_lens import HookedTransformer\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "import einops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPTNeoXTokenizerFast, AutoModelForCausalLM, AutoTokenizer\n",
    "model_name_or_path = \"meta-llama/Meta-Llama-3-8B-Instruct\" \n",
    "# model_name_or_path = \"/data/phillip_guo/circuit-breakers/harmfulness_probe/llama_lora_trained_full_kl\"\n",
    "model_type = \"llama3_8b\" # \n",
    "# model_name_or_path = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "# model_type = \"mistral_7b\"\n",
    "probe_type = \"linear\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path, torch_dtype=torch.bfloat16,          \n",
    "            low_cpu_mem_usage=True,\n",
    "            # attn_implementation=\"flash_attention_2\",\n",
    "            device_map=\"cuda\",\n",
    "            trust_remote_code=True,)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, n_layers, n_heads, d_model):\n",
    "        self.n_layers = n_layers\n",
    "        self.n_heads = n_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "model.cfg = Config(n_layers=32, n_heads=32, d_model=4096)\n",
    "\n",
    "# if model_name_or_path == \"mistralai/Mistral-7B-Instruct-v0.1\":\n",
    "#     real_model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "#     real_model = AutoModelForCausalLM.from_pretrained(real_model_name, torch_dtype=torch.bfloat16)\n",
    "save_dir = f\"lora_trained_{model_type}_{probe_type}\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "cache_layers = [10, 20, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 41,943,040 || all params: 8,072,204,288 || trainable%: 0.5196\n"
     ]
    }
   ],
   "source": [
    "# for lora setup\n",
    "from peft import LoraConfig, get_peft_model\n",
    "target_modules = [\n",
    "    \"q_proj\",\n",
    "    \"k_proj\",\n",
    "    \"v_proj\",\n",
    "    \"o_proj\",\n",
    "    \"gate_proj\",\n",
    "    \"up_proj\",\n",
    "    \"down_proj\",\n",
    "]\n",
    "lora_dropout = 0.05\n",
    "lora_r = 16\n",
    "lora_alpha = 16\n",
    "bias = \"none\"\n",
    "task_type = \"CAUSAL_LM\"\n",
    "layers_to_transform = [i for i in range(max(cache_layers)+1)]\n",
    "\n",
    "lora_args = {\n",
    "    \"r\": lora_r,\n",
    "    \"lora_alpha\": lora_alpha,\n",
    "    \"target_modules\": target_modules,\n",
    "    \"lora_dropout\": lora_dropout,\n",
    "    \"bias\": bias,\n",
    "    \"layers_to_transform\": layers_to_transform,\n",
    "    \"task_type\": task_type,\n",
    "}\n",
    "lora_config = LoraConfig(\n",
    "    **lora_args\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "\n",
    "        # for 1 layer:\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        # # for 2 layers\n",
    "        # self.fc2 = torch.nn.Linear(hidden_size, hidden_size // 2)\n",
    "        # self.fc3 = torch.nn.Linear(hidden_size // 2, output_size)\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "\n",
    "        # for 1 layer\n",
    "        return self.fc2(x)\n",
    "\n",
    "        # # for 2 layers\n",
    "        # x = self.relu(self.fc2(x))\n",
    "        # return self.fc3(x)\n",
    "\n",
    "class Linear(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.fc = torch.nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "class Scale(torch.nn.Module):\n",
    "    def __init__(self, m, scale: float = 100):\n",
    "        super().__init__()\n",
    "        self.m = m\n",
    "        self.scale = torch.nn.Parameter(torch.tensor(1.0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.m(x) * self.scale\n",
    "\n",
    "def zero_init(m):\n",
    "    # if isinstance(m, torch.nn.Linear):\n",
    "    #     m.weight.data.zero_()\n",
    "    #     if m.bias is not None:\n",
    "    #         m.bias.data.zero_()\n",
    "    for name, p in m.named_parameters():\n",
    "        p.data.zero_()\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Linear probe\n",
      "Using Linear probe\n",
      "Using Linear probe\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 32\n",
    "probe_dict = {}\n",
    "for layer_i in cache_layers:\n",
    "    # probe_dict[layer_i] = Scale(zero_init(MLP(model.cfg.d_model, hidden_size, 1))).cuda()\n",
    "    if probe_type == \"mlp\":\n",
    "        print(\"Using MLP probe\")\n",
    "        probe_dict[layer_i] = Scale(MLP(model.cfg.d_model, hidden_size, 1)).cuda()\n",
    "    elif probe_type == \"linear\":\n",
    "        print(\"Using Linear probe\")\n",
    "        probe_dict[layer_i] = Scale(Linear(model.cfg.d_model, 1)).cuda()\n",
    "    else:\n",
    "        raise ValueError(f\"Probe type {probe_type} not recognized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip llama3 chat template\n",
    "# 'prompt' column looks like: <|begin_of_text|><|start_header_id|>user<|end_header_id|> Can you tell me about some of the notable start-ups operating in Sao Paulo's tech scene?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "# include_system_prompt = False\n",
    "\n",
    "def strip_template(text, handle_begin_assistant=False):\n",
    "    stripped_text = text.split(\"<|eot_id|>\")[0].split(\"<|end_header_id|>\")[1].strip()\n",
    "    # if there is any punctuation at the end (., !, ?), remove it\n",
    "    if stripped_text[-1] in ['.', '!']:\n",
    "        stripped_text = stripped_text[:-1]\n",
    "    if handle_begin_assistant:\n",
    "        # there is some contant after \"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\n",
    "        assistant_text = text.split(\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\")[1] \n",
    "        # strip whitespace\n",
    "        assistant_text = assistant_text.strip()\n",
    "        return stripped_text, assistant_text\n",
    "    else:\n",
    "        return stripped_text\n",
    "\n",
    "def apply_chat_template(prompt_list):\n",
    "    new_prompt_list = []\n",
    "    for prompt in prompt_list:\n",
    "        prompt = tokenizer.apply_chat_template([{\"role\": \"system\", \"content\": \"You are a helpful AI Assistant!\"}, {\"role\": \"user\", \"content\": prompt}], tokenize=False) + \"\\n\\n\"\n",
    "        new_prompt_list.append(prompt)\n",
    "    return new_prompt_list\n",
    "\n",
    "def add_output_and_get_output_pos(prompt_list=None, output_list=None, tokenizer=tokenizer, dataset=None, first_n=None, assert_end_newline=False, add_space_between_output_and_input=False, remove_bos_token=True):\n",
    "    # if dataset is not None:\n",
    "    #     if first_n is None:\n",
    "    #         first_n = len(dataset[\"prompt\"])\n",
    "    #     tokenized_prompts = tokenizer(dataset[\"prompt\"][:first_n]).input_ids\n",
    "    #     if add_space_between_output_and_input:\n",
    "    #         full_messages = [x + \"\\n\\n\" + y for x, y in zip(dataset[\"prompt\"][:first_n], dataset[\"completion\"][:first_n])]\n",
    "    #     else:\n",
    "    #         full_messages = [x + y for x, y in zip(dataset[\"prompt\"][:first_n], dataset[\"completion\"][:first_n])]\n",
    "    # else:\n",
    "    if dataset is not None:\n",
    "        prompt_list = dataset[\"prompt\"]\n",
    "        output_list = dataset[\"completion\"]\n",
    "    if add_space_between_output_and_input:\n",
    "        prompt_list = [x + \" \" for x in prompt_list]\n",
    "    if first_n is None:\n",
    "        first_n = len(prompt_list)\n",
    "    if remove_bos_token:\n",
    "        for i in range(len(prompt_list)):\n",
    "            if tokenizer.bos_token in prompt_list[i]:\n",
    "                prompt_list[i] = prompt_list[i].replace(tokenizer.bos_token, \"\")\n",
    "                # also remove the leading whitespace if it exists\n",
    "                if prompt_list[i][0] == \" \":\n",
    "                    prompt_list[i] = prompt_list[i][1:]\n",
    "    tokenized_prompts = tokenizer(prompt_list[:first_n])\n",
    "    full_messages = [x + y for x, y in zip(prompt_list[:first_n], output_list[:first_n])]\n",
    "    tokenized_full_messages = tokenizer(full_messages).input_ids\n",
    "\n",
    "    end_input_positions = [len(tokenized_prompts[i]) - len(tokenized_full_messages[i]) - 1 for i in range(len(full_messages))]\n",
    "    \n",
    "    if assert_end_newline:\n",
    "        tokenized_full_messages = tokenizer(full_messages, padding=True, return_tensors=\"pt\").input_ids\n",
    "        assert (tokenized_full_messages[range(len(end_input_positions)), end_input_positions] == tokenizer(\"\\n\\n\").input_ids[-1]).all(), f\"Last token is not eos_token_id\"\n",
    "    return full_messages, end_input_positions\n",
    "\n",
    "\n",
    "# harmbench_behaviors = pd.read_csv(\"tasks/harmbench/data/harmbench_data/behavior_datasets/harmbench_behaviors_text_all.csv\").set_index(\"BehaviorID\")\n",
    "\n",
    "# for attack_name in test_attacks:\n",
    "#     # open tasks/harmbench/data/harmbench_concise/{attack_name}/llama2_7b/test_cases/test_cases.json\n",
    "#     test_cases = pd.read_json(f\"tasks/harmbench/data/harmbench_concise/{attack_name}/{model_type}/test_cases/test_cases.json\").T.rename({0: attack_name}, axis=1)\n",
    "#     test_cases.index.name = \"BehaviorID\"\n",
    "#     harmbench_behaviors = harmbench_behaviors.join(test_cases, on=\"BehaviorID\")\n",
    "\n",
    "# harmbench_behaviors = harmbench_behaviors.query(\"FunctionalCategory == 'standard' or FunctionalCategory == 'contextual'\").rename({\"Behavior\": \"DirectRequest\"}, axis=1)\n",
    "# print(harmbench_behaviors.shape)\n",
    "\n",
    "# # randomly harmbench_behaviors split 1/3-1/3-1/3 train-val-test\n",
    "# train_harmbench_behaviors = harmbench_behaviors.sample(frac=1/3, random_state=42)\n",
    "# val_harmbench_behaviors = harmbench_behaviors.drop(train_harmbench_behaviors.index).sample(frac=1/3, random_state=42)\n",
    "# test_harmbench_behaviors = harmbench_behaviors.drop(train_harmbench_behaviors.index).drop(val_harmbench_behaviors.index)\n",
    "\n",
    "# attack_names = [\"DirectRequest\"] + test_attacks\n",
    "\n",
    "# custom_clean_data = pd.read_csv(\"tasks/harmbench/data/clean_behaviors.csv\")\n",
    "\n",
    "\n",
    "add_space_between_output_and_input = False # True if model_type == \"mistral_7b\" else False\n",
    "\n",
    "# load from Mechanistic-Anomaly-Detection/llama3-jailbreaks\n",
    "hf_dataset_path = f\"PhillipGuo/{model_type}_prompt_completion_dataset\"\n",
    "\n",
    "benign_train_dataset = load_dataset(hf_dataset_path, split=\"ultrachat_train\")\n",
    "# split into train and val\n",
    "benign_train_dataset = benign_train_dataset.train_test_split(test_size=0.2, shuffle=False)\n",
    "benign_train_dataset, benign_val_dataset = benign_train_dataset[\"train\"], benign_train_dataset[\"test\"]\n",
    "benign_test_dataset = load_dataset(hf_dataset_path, split=\"ultrachat_test\")\n",
    "xstest_dataset = load_dataset(hf_dataset_path, split=\"xstest\")\n",
    "\n",
    "circuit_breakers_train_dataset = load_dataset(hf_dataset_path, split=\"circuit_breakers_harmful_train\")\n",
    "circuit_breakers_train_dataset = circuit_breakers_train_dataset.train_test_split(test_size=0.2, shuffle=False)\n",
    "circuit_breakers_train_dataset, circuit_breakers_test_dataset = circuit_breakers_train_dataset[\"train\"], circuit_breakers_train_dataset[\"test\"]\n",
    "# circuit_breakers_test_dataset = load_dataset(hf_dataset_path, split=\"circuit_breakers_harmful_val\")\n",
    "circuit_breakers_train_dataset = circuit_breakers_train_dataset.train_test_split(test_size=0.2, shuffle=False)\n",
    "circuit_breakers_train_dataset, circuit_breakers_test_dataset = circuit_breakers_train_dataset[\"train\"], circuit_breakers_train_dataset[\"test\"]\n",
    "circuit_breakers_refusal_train_dataset = load_dataset(hf_dataset_path, split=\"circuit_breakers_refusal_train\")\n",
    "\n",
    "# mt_bench_dataset = load_dataset(hf_dataset_path, split=\"mt_bench\")\n",
    "# or_bench_dataset = load_dataset(hf_dataset_path, split=\"or_bench\")\n",
    "# wildchat_dataset = load_dataset(hf_dataset_path, split=\"wildchat\")\n",
    "\n",
    "n_train_prompts = 1500\n",
    "n_val_prompts = 200\n",
    "n_test_prompts = 500\n",
    "\n",
    "all_prompts = {}\n",
    "\n",
    "assert_end_newline = model_type == \"llama3_8b\"\n",
    "all_prompts[\"ultrachat_train\"] = add_output_and_get_output_pos(dataset=benign_train_dataset, first_n=n_train_prompts, add_space_between_output_and_input=add_space_between_output_and_input, assert_end_newline=assert_end_newline)\n",
    "all_prompts[\"ultrachat_val\"] = add_output_and_get_output_pos(dataset=benign_val_dataset, first_n=n_val_prompts, add_space_between_output_and_input=add_space_between_output_and_input, assert_end_newline=assert_end_newline)\n",
    "all_prompts[\"ultrachat_test\"] = add_output_and_get_output_pos(dataset=benign_test_dataset, first_n=n_test_prompts, add_space_between_output_and_input=add_space_between_output_and_input, assert_end_newline=assert_end_newline)\n",
    "all_prompts[\"xstest\"] = add_output_and_get_output_pos(dataset=xstest_dataset, first_n=n_train_prompts, add_space_between_output_and_input=add_space_between_output_and_input, assert_end_newline=assert_end_newline)\n",
    "all_prompts[\"circuit_breakers_train\"] = add_output_and_get_output_pos(dataset=circuit_breakers_train_dataset, first_n=n_train_prompts, add_space_between_output_and_input=add_space_between_output_and_input, assert_end_newline=assert_end_newline)\n",
    "all_prompts[\"circuit_breakers_test\"] = add_output_and_get_output_pos(dataset=circuit_breakers_test_dataset, first_n=n_test_prompts, add_space_between_output_and_input=add_space_between_output_and_input, assert_end_newline=assert_end_newline)\n",
    "all_prompts[\"circuit_breakers_refusal_train\"] = add_output_and_get_output_pos(dataset=circuit_breakers_refusal_train_dataset, first_n=n_train_prompts, add_space_between_output_and_input=add_space_between_output_and_input, assert_end_newline=assert_end_newline)\n",
    "# all_prompts[\"mt_bench\"] = add_output_and_get_output_pos(dataset=mt_bench_dataset, first_n=n_test_prompts, add_space_between_output_and_input=add_space_between_output_and_input)\n",
    "# all_prompts[\"or_bench\"] = add_output_and_get_output_pos(dataset=or_bench_dataset, first_n=n_test_prompts, add_space_between_output_and_input=add_space_between_output_and_input)\n",
    "# all_prompts[\"wildchat\"] = add_output_and_get_output_pos(dataset=wildchat_dataset, first_n=n_test_prompts, add_space_between_output_and_input=add_space_between_output_and_input)\n",
    "\n",
    "\n",
    "\n",
    "# test_attacks = [\"GCG\", \"GCG_T\", \"TAP_T\", \"HumanJailbreaks\", \"DirectRequest\"]\n",
    "# attack_test_val_split = {\"GCG\": False, \"GCG_T\": False, \"TAP_T\": False, \"HumanJailbreaks\": False, \"DirectRequest\": False}\n",
    "\n",
    "# attack_datasets = {}\n",
    "# for attack_name in test_attacks:\n",
    "#     attack_datasets[attack_name] = load_dataset(hf_dataset_path, split=f\"{attack_name}\")\n",
    "\n",
    "# for attack_name in test_attacks:\n",
    "#     prompts, end_input_positions = add_output_and_get_output_pos(dataset=attack_datasets[attack_name], add_space_between_output_and_input=add_space_between_output_and_input)\n",
    "#     if attack_test_val_split[attack_name]:\n",
    "#         # 50-50 split\n",
    "#         n_test_prompts = len(prompts) // 2\n",
    "#         # first n_test_prompts are test, next n_test_prompts are val\n",
    "#         all_prompts[f\"{attack_name}_test\"] = (prompts[:n_test_prompts], end_input_positions[:n_test_prompts])\n",
    "#         all_prompts[f\"{attack_name}_val\"] = (prompts[n_test_prompts:], end_input_positions[n_test_prompts:])\n",
    "#     else:\n",
    "#         all_prompts[f\"{attack_name}_test\"] = (prompts, end_input_positions)\n",
    "\n",
    "\n",
    "# attack_names = test_attacks\n",
    "\n",
    "# combine into benign_train, shuffle\n",
    "\n",
    "benign_train_prompts = all_prompts[\"ultrachat_train\"][0] + all_prompts[\"xstest\"][0]# + all_prompts[\"circuit_breakers_refusal_train\"][0]\n",
    "benign_train_end_input_positions = all_prompts[\"ultrachat_train\"][1] + all_prompts[\"xstest\"][1]# + all_prompts[\"circuit_breakers_refusal_train\"][1]\n",
    "\n",
    "# sample n_train_prompts from benign_train_prompts\n",
    "sample_indices = np.random.choice(len(benign_train_prompts), n_train_prompts, replace=False)\n",
    "benign_train_prompts = [benign_train_prompts[i] for i in sample_indices]\n",
    "benign_train_end_input_positions = [benign_train_end_input_positions[i] for i in sample_indices]\n",
    "\n",
    "all_prompts[\"benign_train\"] = (benign_train_prompts, benign_train_end_input_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retain_tokens should be input + output tokens\n",
    "# retain_labels_mask should be 1 for output tokens, 0 for input tokens\n",
    "\n",
    "sample_retain_prompts = all_prompts[\"ultrachat_train\"][0][:4]\n",
    "sample_retain_indices = all_prompts[\"ultrachat_train\"][1][:4] # list of negative numbers, e.g. -23\n",
    "# for each index, get a binary mask which is 1 for all indices after the index\n",
    "sample_retain_tokens = tokenizer(sample_retain_prompts, padding=True, return_tensors=\"pt\").input_ids.cuda()\n",
    "\n",
    "sample_retain_labels_mask = torch.zeros_like(sample_retain_tokens)\n",
    "for i in range(len(sample_retain_indices)):\n",
    "    sample_retain_labels_mask[i, sample_retain_indices[i]:] = 1\n",
    "sample_retain_labels_mask = sample_retain_labels_mask.bool()\n",
    "\n",
    "sample_forget_prompts = all_prompts[\"circuit_breakers_train\"][0][:4]\n",
    "sample_forget_indices = all_prompts[\"circuit_breakers_train\"][1][:4] # list of negative numbers, e.g. -23\n",
    "# for each index, get a binary mask which is 1 for all indices after the index\n",
    "sample_forget_tokens = tokenizer(sample_forget_prompts, padding=True, return_tensors=\"pt\").input_ids.cuda()\n",
    "sample_forget_labels_mask = torch.zeros_like(sample_forget_tokens)\n",
    "for i in range(len(sample_forget_indices)):\n",
    "    sample_forget_labels_mask[i, sample_forget_indices[i]:] = 1\n",
    "sample_forget_labels_mask = sample_forget_labels_mask.bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6946, device='cuda:0')\n",
      "tensor(0.6826, device='cuda:0')\n",
      "tensor(0.9565, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "retain_losses = []\n",
    "with torch.no_grad():\n",
    "    with torch.autocast(device_type=\"cuda\"):\n",
    "        hidden_states = model(input_ids=sample_retain_tokens, output_hidden_states=True).hidden_states\n",
    "        for layer_i in probe_dict:\n",
    "            # masked_hidden_states = hidden_states[layer_i][:, sample_retain_labels_mask]\n",
    "            # apply probe to hidden_states[layer_i]\n",
    "            probe_outputs = probe_dict[layer_i](hidden_states[layer_i])\n",
    "            # print(((torch.nn.functional.binary_cross_entropy_with_logits(probe_outputs, torch.zeros_like(probe_outputs), reduction=\"none\")[:, :, 0] * sample_retain_labels_mask).sum()) / sample_retain_labels_mask.sum())\n",
    "            print(torch.nn.functional.binary_cross_entropy_with_logits(probe_outputs, torch.zeros_like(probe_outputs), reduction=\"none\")[sample_retain_labels_mask].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ProbingDataset(Dataset):\n",
    "    def __init__(self, benign_prompts, benign_end_positions, harmful_prompts, harmful_end_positions, tokenizer, sft_prompts=None, sft_end_positions=None, sft_benign=True):\n",
    "        self.benign_prompts = benign_prompts\n",
    "        self.benign_end_positions = benign_end_positions\n",
    "        self.harmful_prompts = harmful_prompts\n",
    "        self.harmful_end_positions = harmful_end_positions\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sft_benign = sft_benign\n",
    "        self.sft_prompts = sft_prompts\n",
    "        self.sft_end_positions = sft_end_positions\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.benign_prompts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        retain_prompt = self.benign_prompts[idx]\n",
    "        retain_end_pos = self.benign_end_positions[idx]\n",
    "        forget_prompt = self.harmful_prompts[idx % len(self.harmful_prompts)]\n",
    "        forget_end_pos = self.harmful_end_positions[idx % len(self.harmful_prompts)]\n",
    "        \n",
    "        return_dict = {\n",
    "            'retain_prompt': retain_prompt,\n",
    "            'retain_end_pos': retain_end_pos,\n",
    "            'forget_prompt': forget_prompt,\n",
    "            'forget_end_pos': forget_end_pos\n",
    "        }\n",
    "        if self.sft_benign:\n",
    "            if self.sft_prompts is None:\n",
    "                sft_prompt = retain_prompt\n",
    "                sft_end_pos = retain_end_pos\n",
    "            else:\n",
    "                sft_prompt = self.sft_prompts[idx]\n",
    "                sft_end_pos = self.sft_end_positions[idx]\n",
    "            return_dict[\"sft_prompt\"] = sft_prompt\n",
    "            return_dict[\"sft_end_pos\"] = sft_end_pos\n",
    "\n",
    "        return return_dict\n",
    "\n",
    "def collate_fn(batch, tokenizer, attack_seq=None):\n",
    "    retain_prompts = [item['retain_prompt'] for item in batch]\n",
    "    retain_end_pos = [item['retain_end_pos'] for item in batch]\n",
    "    forget_prompts = [item['forget_prompt'] for item in batch]\n",
    "    forget_end_pos = [item['forget_end_pos'] for item in batch]\n",
    "    if 'sft_prompt' in batch[0]:\n",
    "        sft_prompts = [item['sft_prompt'] for item in batch]\n",
    "        sft_end_pos = [item['sft_end_pos'] for item in batch]\n",
    "\n",
    "    retain_tokenized = tokenizer(retain_prompts, padding=True, return_tensors=\"pt\")\n",
    "    forget_tokenized = tokenizer(forget_prompts, padding=True, return_tensors=\"pt\")\n",
    "    retain_tokens = retain_tokenized.input_ids\n",
    "    forget_tokens = forget_tokenized.input_ids\n",
    "\n",
    "    retain_labels_mask = torch.zeros_like(retain_tokens, dtype=torch.bool)\n",
    "    forget_labels_mask = torch.zeros_like(forget_tokens, dtype=torch.bool)\n",
    "\n",
    "    if attack_seq is not None:\n",
    "        assert attack_seq in [\"total\", \"input\", \"output\"]\n",
    "        retain_attack_mask = torch.zeros_like(retain_tokens, dtype=torch.bool)\n",
    "        forget_attack_mask = torch.zeros_like(forget_tokens, dtype=torch.bool)\n",
    "\n",
    "    if attack_seq == \"total\":\n",
    "        retain_attack_mask = retain_tokenized.attention_mask\n",
    "        forget_attack_mask = forget_tokenized.attention_mask\n",
    "\n",
    "    if 'sft_prompt' in batch[0]:\n",
    "        sft_tokenized = tokenizer(sft_prompts, padding=True, return_tensors=\"pt\")\n",
    "        sft_tokens = sft_tokenized.input_ids\n",
    "        sft_labels_mask = torch.zeros_like(sft_tokens, dtype=torch.bool)\n",
    "\n",
    "    for i, (r_pos, f_pos) in enumerate(zip(retain_end_pos, forget_end_pos)):\n",
    "        retain_labels_mask[i, r_pos:] = 1\n",
    "        forget_labels_mask[i, f_pos:] = 1\n",
    "        if attack_seq == \"input\":\n",
    "            retain_attack_mask[i, :r_pos+1] = 1\n",
    "            forget_attack_mask[i, :f_pos+1] = 1\n",
    "        if attack_seq == \"output\":\n",
    "            retain_attack_mask[i, r_pos:] = 1\n",
    "            forget_attack_mask[i, f_pos:] = 1\n",
    "\n",
    "    retain_labels_mask = retain_labels_mask.bool()\n",
    "    forget_labels_mask = forget_labels_mask.bool()\n",
    "\n",
    "    if attack_seq is not None:\n",
    "        retain_attack_mask = retain_attack_mask.bool()\n",
    "        forget_attack_mask = forget_attack_mask.bool()\n",
    "\n",
    "    if 'sft_prompt' in batch[0]:\n",
    "        for i, sft_pos in enumerate(sft_end_pos):\n",
    "            sft_labels_mask[i, sft_pos:] = True\n",
    "        sft_labels_mask = sft_labels_mask.bool()\n",
    "\n",
    "    # make sure these only True if attention mask is True at pos\n",
    "    assert (retain_labels_mask & ~retain_tokenized.attention_mask).sum() == 0\n",
    "    assert (forget_labels_mask & ~forget_tokenized.attention_mask).sum() == 0\n",
    "    if 'sft_prompt' in batch[0]:\n",
    "        assert (sft_labels_mask & ~sft_tokenized.attention_mask).sum() == 0\n",
    "\n",
    "    if attack_seq is not None:\n",
    "        retain_attack_mask = retain_attack_mask & retain_tokenized.attention_mask\n",
    "        forget_attack_mask = forget_attack_mask & forget_tokenized.attention_mask\n",
    "\n",
    "\n",
    "    return_dict = {\n",
    "        'retain_tokens': retain_tokens,\n",
    "        'retain_labels_mask': retain_labels_mask,\n",
    "        'forget_tokens': forget_tokens,\n",
    "        'forget_labels_mask': forget_labels_mask,\n",
    "    }\n",
    "    if 'sft_prompt' in batch[0]:\n",
    "        return_dict[\"sft_tokens\"] = sft_tokens\n",
    "        return_dict[\"sft_labels_mask\"] = sft_labels_mask\n",
    "    \n",
    "    if attack_seq is not None:\n",
    "        return_dict[\"retain_attack_mask\"] = retain_attack_mask\n",
    "        return_dict[\"forget_attack_mask\"] = forget_attack_mask\n",
    "    return return_dict\n",
    "\n",
    "# Create the dataset\n",
    "probing_dataset = ProbingDataset(\n",
    "    all_prompts[\"benign_train\"][0],\n",
    "    all_prompts[\"benign_train\"][1],\n",
    "    all_prompts[\"circuit_breakers_train\"][0],\n",
    "    all_prompts[\"circuit_breakers_train\"][1],\n",
    "    tokenizer,\n",
    "    sft_benign=False\n",
    ")\n",
    "# Create the dataloader\n",
    "batch_size = 4  # Adjust as needed\n",
    "probing_dataloader = DataLoader(\n",
    "    probing_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda b: collate_fn(b, tokenizer, attack_seq=\"total\")\n",
    ")\n",
    "\n",
    "# Example usage:\n",
    "for batch in probing_dataloader:\n",
    "    retain_tokens = batch['retain_tokens']\n",
    "    retain_labels_mask = batch['retain_labels_mask']\n",
    "    forget_tokens = batch['forget_tokens']\n",
    "    forget_labels_mask = batch['forget_labels_mask']\n",
    "    # sft_tokens = batch['sft_tokens']\n",
    "    # sft_labels_mask = batch['sft_labels_mask']\n",
    "    # Use these tensors in your training loop\n",
    "    # ...\n",
    "\n",
    "    break  # Remove this line when using in actual training loop\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add refusal data to sft\n",
    "\n",
    "\n",
    "sft_dataset = ProbingDataset(\n",
    "    all_prompts[\"benign_train\"][0] + all_prompts[\"circuit_breakers_refusal_train\"][0],\n",
    "    all_prompts[\"benign_train\"][1] + all_prompts[\"circuit_breakers_refusal_train\"][1],\n",
    "    all_prompts[\"ultrachat_train\"][0],\n",
    "    all_prompts[\"ultrachat_train\"][1],\n",
    "    tokenizer,\n",
    "    sft_benign=True\n",
    ")\n",
    "\n",
    "sft_dataloader = DataLoader(\n",
    "    sft_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda b: collate_fn(b, tokenizer)\n",
    ")\n",
    "\n",
    "# Example usage:\n",
    "for batch in sft_dataloader:\n",
    "    sft_tokens = batch['sft_tokens']\n",
    "    sft_labels_mask = batch['sft_labels_mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from latent_at.lat_helpers import *\n",
    "\n",
    "def compute_probe_loss(\n",
    "    model,\n",
    "    probe_dict,\n",
    "    retain_tokens,\n",
    "    retain_labels_mask,\n",
    "    forget_tokens,\n",
    "    forget_labels_mask,\n",
    "    coefs\n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "    Probe dict should have keys as target layers.\n",
    "    towards_labels: torch.Tensor, 1d, shape (batch_size)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Computes towards_loss + away_loss as defined in HarmBench\n",
    "    losses = {\"total\": 0}\n",
    "\n",
    "    if retain_tokens is not None:\n",
    "        retain_losses = []\n",
    "        with torch.autocast(device_type=\"cuda\"):\n",
    "            hidden_states = model(input_ids=retain_tokens, output_hidden_states=True).hidden_states\n",
    "            for layer_i in probe_dict:\n",
    "                probe_outputs = probe_dict[layer_i](hidden_states[layer_i])\n",
    "                retain_losses.append(torch.nn.functional.binary_cross_entropy_with_logits(probe_outputs, torch.zeros_like(probe_outputs), reduction=\"none\")[retain_labels_mask].mean())\n",
    "\n",
    "        summed_retain_losses = torch.stack(retain_losses).sum()\n",
    "        (coefs[\"retain\"] * summed_retain_losses).backward()\n",
    "        for layer_idx, layer_i in enumerate(probe_dict):\n",
    "            losses[f\"retain_l{layer_i}\"] = retain_losses[layer_idx].item()\n",
    "        losses[\"total\"] += summed_retain_losses.item()\n",
    "        \n",
    "    if forget_tokens is not None:\n",
    "        forget_losses = []\n",
    "        with torch.autocast(device_type=\"cuda\"):\n",
    "            hidden_states = model(input_ids=forget_tokens, output_hidden_states=True).hidden_states\n",
    "            for layer_i in probe_dict:\n",
    "                # apply probe to hidden_states[layer_i]\n",
    "                probe_outputs = probe_dict[layer_i](hidden_states[layer_i])\n",
    "                forget_losses.append(torch.nn.functional.binary_cross_entropy_with_logits(probe_outputs, torch.ones_like(probe_outputs), reduction=\"none\")[forget_labels_mask].mean())\n",
    "\n",
    "        summed_forget_losses = torch.stack(forget_losses).sum()\n",
    "        (coefs[\"forget\"] * summed_forget_losses).backward()\n",
    "        # losses[\"forget\"] = summed_forget_losses.item()\n",
    "        for layer_idx, layer_i in enumerate(probe_dict):\n",
    "            losses[f\"forget_l{layer_i}\"] = forget_losses[layer_idx].item()\n",
    "        losses[\"total\"] += summed_forget_losses.item()\n",
    "    \n",
    "    return losses\n",
    "\n",
    "# may also want to train on examples tha\n",
    "def do_adversary_probe_step(\n",
    "    model,\n",
    "    probe_dict,\n",
    "    batch,\n",
    "    losses_dict,\n",
    "    coefs,\n",
    "    log_loss=False\n",
    "):\n",
    "    \"\"\"\n",
    "    For adversary, if coefs[\"forget\"] > 0, then adversary is trying to make model output 0s on forget_tokens.\n",
    "    If coefs[\"retain\"] > 0, then adversary is trying to make model output 1s on retain_tokens.\n",
    "    \"\"\"\n",
    "    include_towards_loss = coefs[\"forget\"] > 0\n",
    "    include_away_loss = coefs[\"retain\"] > 0\n",
    "\n",
    "    # Load batched data\n",
    "    if include_towards_loss:\n",
    "        toward_tokens = batch[\"forget_tokens\"].cuda()\n",
    "        toward_labels_mask = batch[\"forget_labels_mask\"].cuda()\n",
    "    else:\n",
    "        toward_tokens = None\n",
    "        toward_labels_mask = None\n",
    "\n",
    "    if include_away_loss:\n",
    "        away_tokens = batch[\"retain_tokens\"].cuda()\n",
    "        away_labels_mask = batch[\"retain_labels_mask\"].cuda()\n",
    "    else:\n",
    "        away_tokens = None\n",
    "        away_labels_mask = None\n",
    "\n",
    "    # print(f\"{toward_tokens=}\\n{toward_labels_mask=}\\n{away_tokens=}\\n{away_labels_mask=}\\n\")\n",
    "    # Optimize loss function\n",
    "    loss = compute_probe_loss(\n",
    "        model=model,\n",
    "        probe_dict=probe_dict,\n",
    "        retain_tokens=toward_tokens, # this is reversed because attacker wants model to think forget is retain\n",
    "        retain_labels_mask=toward_labels_mask,\n",
    "        forget_tokens=away_tokens, # typically this is not applied\n",
    "        forget_labels_mask=away_labels_mask,\n",
    "        coefs=coefs,\n",
    "    )\n",
    "    \n",
    "    # Log loss in dictionary\n",
    "    if log_loss:\n",
    "        for key in loss:\n",
    "            losses_dict[\"adv_\"+key] = loss[key]\n",
    "\n",
    "def do_defense_probe_step(\n",
    "    model,\n",
    "    probe_dict,\n",
    "    batch,\n",
    "    losses_dict,\n",
    "    wrappers,\n",
    "    sft_batch,\n",
    "    coefs,\n",
    "    log_loss=True,\n",
    "    device=\"cuda\",\n",
    "    adversary_only_on_forget=True\n",
    "):\n",
    "    \"\"\"\n",
    "    For defense, if coefs[\"retain\"] > 0, then defense is trying to make model output 0s on retain_tokens.\n",
    "    If coefs[\"forget\"] > 0, then defense is trying to make model output 1s on forget_tokens.\n",
    "    \"\"\"\n",
    "    include_towards_loss = coefs[\"retain\"] > 0\n",
    "    include_away_loss = coefs[\"forget\"] > 0\n",
    "    # Load batched data\n",
    "    if include_towards_loss:\n",
    "        toward_tokens = batch[\"retain_tokens\"].to(device)\n",
    "        toward_labels_mask = batch[\"retain_labels_mask\"].to(device)\n",
    "        if adversary_only_on_forget:\n",
    "            for wrapper in wrappers:\n",
    "                wrapper.enabled = False\n",
    "            retain_loss = compute_probe_loss(\n",
    "                model=model,\n",
    "                probe_dict=probe_dict,\n",
    "                retain_tokens=toward_tokens,\n",
    "                retain_labels_mask=toward_labels_mask,\n",
    "                forget_tokens=None,\n",
    "                forget_labels_mask=None,\n",
    "                coefs=coefs,\n",
    "            )\n",
    "            for wrapper in wrappers:\n",
    "                wrapper.enabled = True\n",
    "\n",
    "    else:\n",
    "        toward_tokens = None\n",
    "        toward_labels_mask = None\n",
    "    \n",
    "    if include_away_loss:\n",
    "        away_tokens = batch[\"forget_tokens\"].to(device)\n",
    "        away_labels_mask = batch[\"forget_labels_mask\"].to(device)\n",
    "        if adversary_only_on_forget:\n",
    "            forget_loss = compute_probe_loss(\n",
    "                model=model,\n",
    "                probe_dict=probe_dict,\n",
    "                retain_tokens=None,\n",
    "                retain_labels_mask=None,\n",
    "                forget_tokens=away_tokens,\n",
    "                forget_labels_mask=away_labels_mask,\n",
    "                coefs=coefs,\n",
    "            )\n",
    "    else:\n",
    "        away_tokens = None\n",
    "        away_labels_mask = None\n",
    "    \n",
    "    if not adversary_only_on_forget:\n",
    "        loss = compute_probe_loss(\n",
    "            model=model,\n",
    "            probe_dict=probe_dict,\n",
    "            retain_tokens=toward_tokens,\n",
    "            retain_labels_mask=toward_labels_mask,\n",
    "            forget_tokens=away_tokens,\n",
    "            forget_labels_mask=away_labels_mask,\n",
    "            coefs=coefs,\n",
    "        )\n",
    "    else:\n",
    "        loss = {}\n",
    "        total_loss = 0\n",
    "        # merge two losses together, excepting total\n",
    "        if include_towards_loss:\n",
    "            for key in retain_loss:\n",
    "                if key != \"total\":\n",
    "                    loss[key] = retain_loss[key]\n",
    "                else:\n",
    "                    total_loss += retain_loss[\"total\"]\n",
    "        if include_away_loss:\n",
    "            for key in forget_loss:\n",
    "                if key != \"total\":\n",
    "                    loss[key] = forget_loss[key]\n",
    "                else:\n",
    "                    total_loss += forget_loss[\"total\"]\n",
    "        loss[\"total\"] = total_loss\n",
    "\n",
    "\n",
    "    if coefs[\"sft\"] > 0:\n",
    "        sft_tokens = sft_batch[\"sft_tokens\"].to(device)\n",
    "        sft_labels_mask = sft_batch[\"sft_labels_mask\"].to(device)\n",
    "        for wrapper in wrappers:\n",
    "            wrapper.enabled = False\n",
    "        with torch.autocast(device_type=\"cuda\"):\n",
    "            logits = model(input_ids=sft_tokens).logits\n",
    "            final_logits = logits[:, :-1][sft_labels_mask[:, 1:]]\n",
    "            sft_labels = sft_tokens[:, 1:][sft_labels_mask[:, 1:]]\n",
    "            sft_loss = F.cross_entropy(final_logits, sft_labels)\n",
    "        (coefs[\"sft\"] * sft_loss).backward()\n",
    "        loss[\"sft\"] = sft_loss.item()\n",
    "        loss[\"total\"] += sft_loss.item()\n",
    "        for wrapper in wrappers:\n",
    "            wrapper.enabled = True\n",
    "    \n",
    "    # Log loss in dictionary\n",
    "    if log_loss:\n",
    "        for key in loss:\n",
    "            losses_dict[\"def_\"+key] = loss[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from latent_at.lat_methods import *\n",
    "def projected_gradient_descent_probe(\n",
    "    batch,\n",
    "    model,\n",
    "    probe_dict,\n",
    "    model_layers_module,\n",
    "    layer,\n",
    "    epsilon,\n",
    "    learning_rate,\n",
    "    pgd_iterations,\n",
    "    loss_coefs,\n",
    "    log_loss=True,\n",
    "    return_loss_over_time=False,\n",
    "    device=\"cuda\",\n",
    "    clip_grad=None,\n",
    "    pca_kwargs=None,\n",
    "\n",
    "    dtype=torch.float32\n",
    "):\n",
    "\n",
    "    # Clear and initialize the adversary\n",
    "    clear_hooks(model)\n",
    "    if type(layer) == int:\n",
    "        layer = [layer,]\n",
    "    \n",
    "    if pca_kwargs is not None:\n",
    "        pca_proj = pca_kwargs[\"proj\"]\n",
    "        pca_unproj = pca_kwargs[\"unproj\"]\n",
    "        create_adversary=lambda x: WhitenedGDAdversary(\n",
    "            dim=model.config.hidden_size,\n",
    "            device=device,\n",
    "            epsilon=epsilon,\n",
    "            attack_mask=batch[\"forget_attack_mask\"].to(device),\n",
    "            proj=pca_proj[x], # should be layer\n",
    "            inv_proj=pca_unproj[x],\n",
    "            dtype=dtype\n",
    "        )\n",
    "    else:\n",
    "        create_adversary=lambda x: GDAdversary(\n",
    "            dim=model.config.hidden_size,\n",
    "            device=device,\n",
    "            epsilon=epsilon,\n",
    "            attack_mask=batch[\"forget_attack_mask\"].to(device)\n",
    "        )\n",
    "    \n",
    "    if pgd_iterations > 0:\n",
    "        adversary_locations = [\n",
    "            (f\"{model_layers_module}.{layer_i}\", \"mlp\") for layer_i in layer if type(layer_i) == int\n",
    "        ]\n",
    "        if \"embedding\" in layer:\n",
    "            adversary_locations += [(model_layers_module.replace(\".layers\", \"\"), \"embed_tokens\")]\n",
    "\n",
    "        adversaries, wrappers = add_hooks(\n",
    "            model,\n",
    "            create_adversary=create_adversary,\n",
    "            adversary_locations=adversary_locations,\n",
    "            # adversary_locations = [\n",
    "            #     (f\"{model_layers_module}.{layer_i}\", \"mlp\") for layer_i in layer\n",
    "            # ]\n",
    "        )\n",
    "        params = []\n",
    "        for adv in adversaries:\n",
    "            params += list(adv.parameters())\n",
    "        \n",
    "        # Define optimization utils\n",
    "        adv_optim = torch.optim.AdamW(params, lr=learning_rate)\n",
    "        if return_loss_over_time:\n",
    "            loss_over_time = []\n",
    "        losses = {}\n",
    "    else:\n",
    "        losses = {}\n",
    "        wrappers = []\n",
    "    \n",
    "    \n",
    "    # Optimize adversary to elicit attack labels\n",
    "    for j in range(pgd_iterations):\n",
    "        adv_optim.zero_grad()\n",
    "        do_adversary_probe_step(\n",
    "            model=model,\n",
    "            probe_dict=probe_dict,\n",
    "            batch=batch,\n",
    "            losses_dict=losses,\n",
    "            coefs=loss_coefs,\n",
    "            log_loss=log_loss,\n",
    "        )\n",
    "        zero_nan_grads(adv)\n",
    "        if clip_grad is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                adv.parameters(), clip_grad)\n",
    "        adv_optim.step()\n",
    "        for adv in adversaries:\n",
    "            adv.clip_attack()\n",
    "\n",
    "        if return_loss_over_time:\n",
    "            loss_over_time.append(copy.deepcopy(losses))\n",
    "\n",
    "    if return_loss_over_time:\n",
    "        return loss_over_time, wrappers\n",
    "    else:\n",
    "        return losses, wrappers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from latent_at.lat_methods import *\n",
    "\n",
    "class ProjectedGradProbeLAT(LATBaseClass):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        probe_dict,\n",
    "        dataloader,\n",
    "        pgd_layers,\n",
    "        model_layers,\n",
    "        epsilon,\n",
    "        init_callback=None,\n",
    "        post_adv_callback=None,\n",
    "        post_def_callback=None,\n",
    "        outer_learning_rate=1e-4,\n",
    "        inner_learning_rate=5e-2,\n",
    "        num_steps=50,\n",
    "        pgd_iterations_per_step=16,\n",
    "        model_iterations_per_step=1,\n",
    "        model_layers_module=\"base_model.model.model.layers\",\n",
    "        only_train_lora=True,\n",
    "        sft_dataloader=None,\n",
    "        adv_loss_coefs={\"forget\":1, \"retain\": 0},\n",
    "        def_loss_coefs={\"forget\":1, \"retain\": 1},\n",
    "        max_batch_per_acc=None,\n",
    "        clip_grad=1.0,\n",
    "        reinitialize_dev_optim=True,\n",
    "        time_limit=None,\n",
    "        device=\"cuda\",\n",
    "        pca_kwargs=None,\n",
    "    ):\n",
    "        \n",
    "        super().__init__(\n",
    "            model=model,\n",
    "            dataloader=dataloader,\n",
    "            model_layers=model_layers,\n",
    "            # model_layers=list(set(model_update_layers) + set(model_loss_layers)),\n",
    "            init_callback=init_callback,\n",
    "            post_adv_callback=post_adv_callback,\n",
    "            post_def_callback=post_def_callback,\n",
    "            model_layers_module=model_layers_module,\n",
    "            only_train_lora=only_train_lora,\n",
    "        )\n",
    "        self.probe_dict = probe_dict\n",
    "        self.pgd_layers = pgd_layers\n",
    "        self.epsilon = epsilon\n",
    "        self.outer_learning_rate = outer_learning_rate\n",
    "        self.inner_learning_rate = inner_learning_rate\n",
    "        self.num_steps = num_steps\n",
    "        self.pgd_iterations_per_step = pgd_iterations_per_step\n",
    "        self.model_iterations_per_step = model_iterations_per_step\n",
    "        self.max_batch_per_acc = max_batch_per_acc\n",
    "        self.clip_grad = clip_grad\n",
    "        self.reinitialize_dev_optim = reinitialize_dev_optim\n",
    "        self.time_limit = time_limit\n",
    "        self.device = device\n",
    "        self.pca_kwargs = pca_kwargs\n",
    "\n",
    "\n",
    "        if sft_dataloader is not None:\n",
    "            assert dataloader.batch_size == sft_dataloader.batch_size\n",
    "            self.sft_dataloader = itertools.cycle(sft_dataloader)\n",
    "        else:\n",
    "            assert def_loss_coefs[\"sft\"] == 0\n",
    "            self.sft_dataloader = None  \n",
    "\n",
    "        self.adv_loss_coefs = normalize_dict(adv_loss_coefs)\n",
    "        self.def_loss_coefs = normalize_dict(def_loss_coefs)\n",
    "        \n",
    "        self.def_optim = torch.optim.AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=self.outer_learning_rate\n",
    "        )\n",
    "        \n",
    "        self.attack_type = \"pgd\"\n",
    "\n",
    "        self.dtype = next(self.model.parameters()).dtype\n",
    "\n",
    "    def train_adversary(self, batch, acc_step, pca_kwargs=None):\n",
    "        return projected_gradient_descent_probe(\n",
    "            batch=batch,\n",
    "            model=self.model,\n",
    "            probe_dict=self.probe_dict,\n",
    "            model_layers_module=self.model_layers_module,\n",
    "            layer=self.pgd_layers,\n",
    "            epsilon=self.epsilon,\n",
    "            learning_rate=self.inner_learning_rate,\n",
    "            pgd_iterations=self.pgd_iterations_per_step,\n",
    "            loss_coefs=self.adv_loss_coefs,\n",
    "            log_loss=not acc_step,\n",
    "            device=self.device,\n",
    "            pca_kwargs=pca_kwargs,\n",
    "            dtype=self.dtype\n",
    "        )\n",
    "\n",
    "    def train_defense(self, batch, sft_batch, wrappers, zero_grad, grad_step):\n",
    "        # Initialize optimizer and loss\n",
    "        losses = {}\n",
    "        if zero_grad:\n",
    "            self.def_optim.zero_grad()\n",
    "        # Compute the defense        \n",
    "        do_defense_probe_step(\n",
    "            model=self.model,\n",
    "            probe_dict=self.probe_dict,\n",
    "            batch=batch,\n",
    "            sft_batch=sft_batch,\n",
    "            losses_dict=losses,\n",
    "            wrappers=wrappers,\n",
    "            coefs=self.def_loss_coefs,\n",
    "\n",
    "            log_loss=grad_step,\n",
    "            device=self.device,\n",
    "        )\n",
    "        zero_nan_grads(self.model)\n",
    "        # Do gradient step\n",
    "        if grad_step:\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.model.parameters(), self.clip_grad)\n",
    "            self.def_optim.step()\n",
    "        return losses\n",
    "    \n",
    "    def lat_training_step(self, epoch, batch, sft_batch, pca_kwargs=None):\n",
    "        # raise NotImplementedError(\"Only implemented training step with accumulation\")\n",
    "        # Train Adversary\n",
    "        self.disable_model_gradients()\n",
    "        losses, wrappers = self.train_adversary(\n",
    "            batch=batch,\n",
    "            acc_step=False,\n",
    "            pca_kwargs=pca_kwargs\n",
    "        )\n",
    "        if self.post_adv_callback is not None:\n",
    "            self.post_adv_callback(losses, epoch=epoch)\n",
    "        # Train model against adversary\n",
    "        self.enable_model_gradients()\n",
    "        for _ in range(self.model_iterations_per_step):\n",
    "            def_losses = self.train_defense(\n",
    "                batch=batch,\n",
    "                sft_batch=sft_batch,\n",
    "                wrappers=wrappers,\n",
    "                zero_grad=True,\n",
    "                grad_step=True,\n",
    "            )\n",
    "        # Log results\n",
    "        losses.update(def_losses)\n",
    "        clear_hooks(self.model)\n",
    "        if self.post_def_callback is not None:\n",
    "            self.post_def_callback(losses, epoch)\n",
    "\n",
    "    def lat_training_step_with_accumulation(self, epoch, batch, sft_batch, pca_kwargs=None):\n",
    "        # Train gradient accumulation version\n",
    "        batch_size = batch[\"retain_tokens\"].shape[0]\n",
    "        acc_steps = list(range(0, batch_size, self.max_batch_per_acc))\n",
    "        acc_wrappers = []\n",
    "        # Train advesaries for each sub-batch\n",
    "        for start_idx in acc_steps:\n",
    "            # Load a subset of the batch\n",
    "            mini_batch = get_minibatch(batch, start_idx, self.max_batch_per_acc)\n",
    "            # print(f\"MINI BATCH: {mini_batch}\")\n",
    "\n",
    "            # Train Adversary\n",
    "            self.disable_model_gradients()\n",
    "            losses, wrappers = self.train_adversary(\n",
    "                batch=mini_batch,\n",
    "                acc_step=start_idx!=acc_steps[-1],\n",
    "                pca_kwargs=pca_kwargs\n",
    "            )\n",
    "            acc_wrappers.append(wrappers)\n",
    "            for wrapper in wrappers:\n",
    "                wrapper.enabled = False\n",
    "        if self.post_adv_callback is not None:\n",
    "            self.post_adv_callback(losses, epoch=epoch)\n",
    "        # Train defense for each sub-batch\n",
    "        for _ in range(self.model_iterations_per_step):\n",
    "            for i, start_idx in enumerate(acc_steps):\n",
    "                # Load in things associated with subbatch\n",
    "                mini_batch = get_minibatch(batch, start_idx, self.max_batch_per_acc)\n",
    "                sft_mini_batch = get_minibatch(sft_batch, start_idx, self.max_batch_per_acc)\n",
    "                wrappers = acc_wrappers[i]\n",
    "                for wrapper in wrappers:\n",
    "                    wrapper.enabled = True                    \n",
    "                # Train model against adversary\n",
    "                self.enable_model_gradients()\n",
    "                def_losses = self.train_defense(\n",
    "                    batch=mini_batch,\n",
    "                    sft_batch=sft_mini_batch,\n",
    "                    wrappers=wrappers,\n",
    "                    zero_grad=start_idx==acc_steps[0],\n",
    "                    grad_step=start_idx==acc_steps[-1],\n",
    "                )\n",
    "                for wrapper in wrappers:\n",
    "                    wrapper.enabled = False\n",
    "        # Log results\n",
    "        losses.update(def_losses)\n",
    "        if self.post_def_callback is not None and start_idx == acc_steps[-1]:\n",
    "            self.post_def_callback(losses, epoch)\n",
    "        clear_hooks(self.model)\n",
    "\n",
    "    def train_epoch(self, epoch, new_pca_projs=None):\n",
    "        # Load batched data\n",
    "        batch = next(self.dataloader)\n",
    "        if self.sft_dataloader is not None:\n",
    "            sft_batch = next(self.sft_dataloader)\n",
    "        else:\n",
    "            sft_batch = None\n",
    "        # Reinitialize optimizer every LAT step\n",
    "        if self.reinitialize_dev_optim:\n",
    "            self.def_optim = torch.optim.AdamW(\n",
    "                self.model.parameters(),\n",
    "                lr=self.outer_learning_rate\n",
    "            )\n",
    "        # Start training loop\n",
    "        if self.max_batch_per_acc is not None:\n",
    "            self.lat_training_step_with_accumulation(\n",
    "                epoch=epoch,\n",
    "                batch=batch,\n",
    "                sft_batch=sft_batch,\n",
    "                pca_kwargs=new_pca_projs\n",
    "            )\n",
    "        else:\n",
    "            self.lat_training_step(\n",
    "                epoch=epoch,\n",
    "                batch=batch,\n",
    "                sft_batch=sft_batch,\n",
    "                pca_kwargs=new_pca_projs\n",
    "            )\n",
    "\n",
    "    def train(self, project_name, name=None, additional_wandb_kwargs=None):\n",
    "        super().train(project_name, additional_wandb_kwargs=additional_wandb_kwargs)\n",
    "        if self.init_callback is not None:\n",
    "            self.init_callback({}, -1)\n",
    "        \n",
    "        use_pca = self.pca_kwargs is not None\n",
    "        if use_pca:\n",
    "            refresh_pca_every = self.pca_kwargs.get(\"refresh_every\", None)\n",
    "            pca_proj = self.pca_kwargs.get(\"proj\", None)\n",
    "            pca_unproj = self.pca_kwargs.get(\"unproj\", None)\n",
    "\n",
    "        epoch_iter = tqdm(range(self.num_steps)) if self.num_steps is not None else tqdm(itertools.count())\n",
    "        start_time = time.time()\n",
    "        for epoch in epoch_iter:\n",
    "            if use_pca and (refresh_pca_every is not None) and (epoch % refresh_pca_every == 0):\n",
    "                if isinstance(self.pgd_layers, list):\n",
    "                    cache_locations = [(f\"{self.model_layers_module}.{layer_i}\", \"mlp\") for layer_i in self.pgd_layers]\n",
    "                else:\n",
    "                    cache_locations = [(f\"{self.model_layers_module}.{self.pgd_layers}\", \"mlp\")]\n",
    "\n",
    "            new_pca_projs = None\n",
    "\n",
    "            # try:\n",
    "            self.train_epoch(epoch, new_pca_projs=new_pca_projs)\n",
    "            # except Exception as e:\n",
    "            #     print(f\"Error at epoch {epoch} of {name}: {e}\")\n",
    "            #     os.makedirs(\"logs\", exist_ok=True)\n",
    "            #     with open(f\"logs/{name}_errors.txt\", \"a\") as f:\n",
    "            #         f.write(f\"Error at epoch {epoch} of {name}: {e}\\n\")\n",
    "            elapsed_time = time.time() - start_time\n",
    "            if self.time_limit is not None and elapsed_time > self.time_limit:\n",
    "                print(f\"Reached {elapsed_time} seconds at epoch {epoch}\")\n",
    "                break\n",
    "        wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.only_train_lora=True\n",
      "config.keys()=dict_keys(['model', 'dataloader', 'model_layers', 'init_callback', 'post_adv_callback', 'post_def_callback', 'only_train_lora', 'model_layers_module', 'probe_dict', 'pgd_layers', 'epsilon', 'outer_learning_rate', 'inner_learning_rate', 'num_steps', 'pgd_iterations_per_step', 'model_iterations_per_step', 'max_batch_per_acc', 'clip_grad', 'reinitialize_dev_optim', 'time_limit', 'device', 'pca_kwargs', 'sft_dataloader', 'adv_loss_coefs', 'def_loss_coefs', 'def_optim', 'attack_type', 'dtype', 'probe_type'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mphilliphguo\u001b[0m (\u001b[33mquirky_lats_at_mats\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `config_exclude_keys` is deprecated. Use `config=wandb.helper.parse_config(config_object, exclude=('key',))` instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/phillip_guo/sae_experiments/wandb/run-20240930_093803-p6dp1rja</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/quirky_lats_at_mats/lora_train_model/runs/p6dp1rja' target=\"_blank\">smart-capybara-27</a></strong> to <a href='https://wandb.ai/quirky_lats_at_mats/lora_train_model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/quirky_lats_at_mats/lora_train_model' target=\"_blank\">https://wandb.ai/quirky_lats_at_mats/lora_train_model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/quirky_lats_at_mats/lora_train_model/runs/p6dp1rja' target=\"_blank\">https://wandb.ai/quirky_lats_at_mats/lora_train_model/runs/p6dp1rja</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [14:05<00:00,  8.45s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>def_forget_l10</td><td>▆▆▅▆▅▅▅▅▅▄▂▄▁▁▁▃▁█▁▁▁▁▁▁▁▁▁▇▁▁▁▁▁▁▃▁▁▁▁▁</td></tr><tr><td>def_forget_l20</td><td>▅▅▅▅▄▃▂▁▁▁▁▄▁▁▁▄▁█▁▂▁▁▁▁▁▁▁▆▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>def_forget_l32</td><td>▅▆▂▄▁▁▁▁▁▁▁█▁▁▁▅▁▇▁▁▁▁▁▁▁▁▁▆▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>def_retain_l10</td><td>▇█▇███▇█▇▅▄▁▅▅█▆▁▁▁▃▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>def_retain_l20</td><td>▇▇▇▇▇▇▇█▄▂▂▁▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>def_retain_l32</td><td>█▅▂▂▇▇▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁</td></tr><tr><td>def_sft</td><td>▆▂▆▃▄▅▅▅▄▃▃▁▆▃▄▆▄█▇▄▄▂▂▆▆▆▄▄▄▄▁▂▅▇▃▇▁▄▁▁</td></tr><tr><td>def_total</td><td>█▇▆▆▆▆▅▅▄▃▂▄▃▂▃▅▂█▃▂▂▁▁▃▃▂▂▆▂▂▁▁▂▃▂▃▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>def_forget_l10</td><td>0.00123</td></tr><tr><td>def_forget_l20</td><td>0.00035</td></tr><tr><td>def_forget_l32</td><td>1e-05</td></tr><tr><td>def_retain_l10</td><td>0.01728</td></tr><tr><td>def_retain_l20</td><td>0.00627</td></tr><tr><td>def_retain_l32</td><td>8e-05</td></tr><tr><td>def_sft</td><td>0.12949</td></tr><tr><td>def_total</td><td>0.15469</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">smart-capybara-27</strong> at: <a href='https://wandb.ai/quirky_lats_at_mats/lora_train_model/runs/p6dp1rja' target=\"_blank\">https://wandb.ai/quirky_lats_at_mats/lora_train_model/runs/p6dp1rja</a><br/> View project at: <a href='https://wandb.ai/quirky_lats_at_mats/lora_train_model' target=\"_blank\">https://wandb.ai/quirky_lats_at_mats/lora_train_model</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240930_093803-p6dp1rja/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def eval_and_log(result, epoch):\n",
    "    wandb.log(result)\n",
    "\n",
    "pgd_trainer = ProjectedGradProbeLAT(\n",
    "    model=model,  # model\n",
    "    probe_dict=probe_dict,\n",
    "    dataloader=probing_dataloader,  # dataloader for lat\n",
    "    sft_dataloader=sft_dataloader,  # dataloader for supervised finetuning\n",
    "    adv_loss_coefs={\"forget\": 1, \"retain\": 0},\n",
    "    def_loss_coefs={\"forget\": 1, \"retain\": 1, \"sft\": 0.5},  # model's loss coefs\n",
    "    pgd_layers=[\"embedding\", 8, 16, 24, 30],  # what layers to attack\n",
    "    model_layers=layers_to_transform,  # what layers to train\n",
    "    epsilon=1.5,  # attack l2 constraint\n",
    "    outer_learning_rate=5e-5,  # model lr\n",
    "    inner_learning_rate=5e-2,  # attacker lr\n",
    "    pgd_iterations_per_step=0,  # how many steps of projected gradient descent to do\n",
    "    model_iterations_per_step=4,  # how many times to train on each step\n",
    "    num_steps=100,  # number of epochs\n",
    "    max_batch_per_acc=2,  # max size of a minibatch\n",
    "    model_layers_module=\"base_model.model.model.layers\",  # where the model layers are\n",
    "    reinitialize_dev_optim=False,\n",
    "    only_train_lora=True,\n",
    "    # post_adv_callback=eval_and_log,\n",
    "    post_def_callback=eval_and_log,\n",
    ")\n",
    "\n",
    "pgd_trainer.train(\n",
    "    project_name=\"lora_train_model\",\n",
    "    name=\"pgd_train_model\",\n",
    "    additional_wandb_kwargs={\n",
    "        \"probe_type\": probe_type,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to hf\n",
    "model.save_pretrained(f\"lora_train_{model_type}_{probe_type}\")\n",
    "torch.save(probe_dict, f\"lora_train_{model_type}_{probe_type}/probe_dict.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "probe_dict.pt: 100%|██████████| 54.6k/54.6k [00:00<00:00, 275kB/s]\n",
      "adapter_model.safetensors: 100%|██████████| 168M/168M [00:05<00:00, 32.3MB/s]\n",
      "Upload 2 LFS files: 100%|██████████| 2/2 [00:05<00:00,  2.69s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/PhillipGuo/lora_train_llama3_8b_linear/commit/fa969f635ad3388d9a8186294598abdae8da7913', commit_message='Upload folder using huggingface_hub', commit_description='', oid='fa969f635ad3388d9a8186294598abdae8da7913', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi, create_repo\n",
    "api = HfApi()\n",
    "\n",
    "# # Upload all the content from the local folder to your remote Space.\n",
    "# # By default, files are uploaded at the root of the repo\n",
    "create_repo(\n",
    "    repo_id=f\"PhillipGuo/lora_train_{model_type}_{probe_type}\",\n",
    "    repo_type=\"model\",\n",
    ")\n",
    "api.upload_folder(\n",
    "    folder_path=f\"lora_train_{model_type}_{probe_type}\",\n",
    "    repo_id=f\"PhillipGuo/lora_train_{model_type}_{probe_type}\",\n",
    "    repo_type=\"model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cb",
   "language": "python",
   "name": "cb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
